<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>爬蟲 - Tag - 程式狂想筆記</title><link>https://malagege.github.io/blog/tags/%E7%88%AC%E8%9F%B2/</link><description>爬蟲 - Tag - 程式狂想筆記</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><lastBuildDate>Sun, 31 Jul 2022 02:22:26 +0000</lastBuildDate><atom:link href="https://malagege.github.io/blog/tags/%E7%88%AC%E8%9F%B2/" rel="self" type="application/rss+xml"/><item><title>Puppeteer 爬蟲小試</title><link>https://malagege.github.io/blog/posts/Puppeteer-%E7%88%AC%E8%9F%B2%E5%B0%8F%E8%A9%A6/</link><pubDate>Sun, 31 Jul 2022 02:22:26 +0000</pubDate><author>malagege</author><guid>https://malagege.github.io/blog/posts/Puppeteer-%E7%88%AC%E8%9F%B2%E5%B0%8F%E8%A9%A6/</guid><description><![CDATA[<h2 id="參考文章">參考文章</h2>
<p><a href="https://eden-liu.com/frontend/taste-webdriverio/" target="_blank" rel="noopener noreffer ">淺嚐 WebDriverIO - Eden Liu</a><br>
<a href="https://ithelp.ithome.com.tw/articles/10241791" target="_blank" rel="noopener noreffer ">【Day8】selenium-webdriver：爬蟲起手式，帶你認識所見即所得的爬蟲工具 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天</a><br>
<a href="https://ithelp.ithome.com.tw/articles/10204195" target="_blank" rel="noopener noreffer ">Day 22 Puppeteer處理lazy load, SSR, 反爬蟲防禦, 高效地爬大量數據 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天</a></p>]]></description></item><item><title>Nodejs 使用 cheerio 做簡單爬蟲</title><link>https://malagege.github.io/blog/posts/Nodejs-%E4%BD%BF%E7%94%A8-cheerio-%E5%81%9A%E7%B0%A1%E5%96%AE%E7%88%AC%E8%9F%B2/</link><pubDate>Sun, 22 Aug 2021 15:57:00 +0000</pubDate><author>malagege</author><guid>https://malagege.github.io/blog/posts/Nodejs-%E4%BD%BF%E7%94%A8-cheerio-%E5%81%9A%E7%B0%A1%E5%96%AE%E7%88%AC%E8%9F%B2/</guid><description>&lt;p>官方文件:&lt;a href="https://github.com/cheeriojs/cheerio/wiki/Chinese-README" target="_blank" rel="noopener noreffer ">Chinese README · cheeriojs/cheerio Wiki&lt;/a>&lt;/p></description></item><item><title>不用程式寫爬蟲記錄(Kimono Desktop)</title><link>https://malagege.github.io/blog/posts/logdown/2016-11-27-1147900/</link><pubDate>Sun, 27 Nov 2016 05:25:00 +0000</pubDate><author>malagege</author><guid>https://malagege.github.io/blog/posts/logdown/2016-11-27-1147900/</guid><description><![CDATA[<p>前幾天看到<a href="http://blog.infographics.tw/2016/11/google-spreadsheet-data-scraping/" target="_blank" rel="noopener noreffer ">無痛爬梳自己來，用 Google Spreadsheet 爬取網頁資料</a><br>
就想之前的Kimono<br>
但現在官網要收掉這個服務<br>
不過有官網友留下kimono desktop edition 離線版程式使用(只有MAC和Windows)<br>
目前不知道有沒有辦法移植到Linux上面玩</p>
<table>
<thead>
<tr>
<th></th>
<th>kimonolabs.com</th>
<th>kimono for desktop</th>
</tr>
</thead>
<tbody>
<tr>
<td>Create APIs with Chrome Ext</td>
<td>v</td>
<td></td>
</tr>
<tr>
<td>Create APIs with Bookmarklet</td>
<td>v</td>
<td>v</td>
</tr>
<tr>
<td>Manage and configure APIs</td>
<td>v</td>
<td>v</td>
</tr>
<tr>
<td>Run APIs manually</td>
<td>v</td>
<td></td>
</tr>
<tr>
<td>Run APIs on a schedule</td>
<td>v</td>
<td></td>
</tr>
<tr>
<td>Cloud hosted API endpoints</td>
<td></td>
<td>v (w/ Firebase)</td>
</tr>
<tr>
<td>Crawling &amp; Pagination</td>
<td>v</td>
<td>v</td>
</tr>
<tr>
<td>Get data behind a login</td>
<td>v</td>
<td>v</td>
</tr>
<tr>
<td>Kimono Apps / Blocks</td>
<td>v</td>
<td></td>
</tr>
<tr>
<td>Google sheets integration</td>
<td>v</td>
<td></td>
</tr>
<tr>
<td>Webhooks &amp; Email alerts</td>
<td>v</td>
<td></td>
</tr>
<tr>
<td>Save scraped data to file</td>
<td>v</td>
<td>v</td>
</tr>
<tr>
<td>CSV &amp; RSS output</td>
<td>v</td>
<td>v</td>
</tr>
</tbody>
</table>
<p>當然離線版沒有這麼多功能，可惜沒有排程可以用<br>
但發現他程式透過NodeJS去寫，好像可以透過API方式去實作<br>
在此先記錄一下筆記</p>]]></description></item><item><title>[Python]使用requests、BeautifulSoup當網頁爬蟲</title><link>https://malagege.github.io/blog/posts/logdown/2014-11-18-python-using-beautifulsoup-and-requests-when-crawler/</link><pubDate>Tue, 18 Nov 2014 05:40:00 +0000</pubDate><author>malagege</author><guid>https://malagege.github.io/blog/posts/logdown/2014-11-18-python-using-beautifulsoup-and-requests-when-crawler/</guid><description><![CDATA[<p>上次參加COSCUP 2014時候，<a href="http://www.slideshare.net/daikeren/news-37154830" target="_blank" rel="noopener noreffer ">電腦不只會幫你選土豆，還會幫你選新聞</a><br>
最近無聊做個小實驗<br>
使用requests、BeautifulSoup實作抓資料存成json<br>
結果發現不會太難</p>]]></description></item></channel></rss>